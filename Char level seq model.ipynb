{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n",
      "Train shape :  (242430, 3)\n",
      "qid              527aac2ce6f12f789fe5\n",
      "question_text                       \"\n",
      "target                              1\n",
      "Name: 420816, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./input/train.csv\")\n",
    "df_test = pd.read_csv(\"./input/test.csv\")\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)\n",
    "\n",
    "df_train_pos = df_train[df_train['target']==1]\n",
    "df_train_neg = df_train[df_train['target']==0].sample(len(df_train_pos)*2,random_state=1)\n",
    "df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "df_train = df_train.sample(frac=1,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "## fill up the missing values\n",
    "# train_X_raw = df_train[\"question_text\"].fillna(\"_##_\").values\n",
    "# test_X_raw = df_test[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "char_dict = {chr(i+96):i for i in range(1,27)}\n",
    "char_dict[' '] = 0 \n",
    "vocab_size = len(char_dict)\n",
    "\n",
    "train_X_filt = []\n",
    "train_Y = []\n",
    "for i in range(len(df_train)):\n",
    "    s=[]\n",
    "    for char in df_train.iloc[i]['question_text'].lower():\n",
    "        if char in char_dict.keys():\n",
    "            s.append(char_dict[char])\n",
    "    if s!=[]:\n",
    "        train_X_filt.append(s)\n",
    "        train_Y.append(df_train.iloc[i]['target'])\n",
    "    else:\n",
    "        print(df_train.iloc[i])\n",
    "train_Y = np.asarray(train_Y)\n",
    "        \n",
    "test_X_filt = []\n",
    "for sent in df_test[\"question_text\"].values:\n",
    "    s=[]\n",
    "    for char in sent.lower():\n",
    "        if char in char_dict.keys():\n",
    "            s.append(char_dict[char])\n",
    "    test_X_filt.append(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is water a resource or not?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.iloc[0]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.14002450201914\n",
      "63.0\n",
      "44.57839614991223\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([7.09324631e-03, 8.39320123e-03, 2.77451258e-03, 8.31683776e-04,\n",
       "        4.75616889e-04, 8.87947349e-07, 1.61444973e-07, 0.00000000e+00,\n",
       "        8.07224863e-08, 8.07224863e-08]),\n",
       " array([  1. ,  52.1, 103.2, 154.3, 205.4, 256.5, 307.6, 358.7, 409.8,\n",
       "        460.9, 512. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for sent in train_X_filt:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "    if max(sent)>50:\n",
    "        print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "# print(len(lengths>200))\n",
    "plt.hist(lengths,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 150\n",
    "# Pad the sentences \n",
    "train_X_filt = pad_sequences(train_X_filt, maxlen=maxlen, padding=\"post\")\n",
    "test_X_filt = pad_sequences(test_X_filt, maxlen=maxlen, padding =\"post\")\n",
    "\n",
    "\n",
    "train_X = np.asarray([to_categorical(x, num_classes=vocab_size) for x in train_X_filt])\n",
    "# test_X_filt = np.asarray([to_categorical(x, num_classes=vocab_size) for x in test_X_filt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242429, 150, 27)\n",
      "(242429,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_X_raw[0])\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 150, 300)          214800    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               4500100   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 4,715,001\n",
      "Trainable params: 4,715,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##model definition\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(CuDNNLSTM(75, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Bidirectional(CuDNNLSTM(150, return_sequences=True,), input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 193943 samples, validate on 48486 samples\n",
      "Epoch 1/100\n",
      "193943/193943 [==============================] - 87s 448us/step - loss: 0.4587 - acc: 0.7832 - f1: 0.6465 - val_loss: 0.3985 - val_acc: 0.8250 - val_f1: 0.6895\n",
      "Epoch 2/100\n",
      "193943/193943 [==============================] - 82s 423us/step - loss: 0.3609 - acc: 0.8458 - f1: 0.7539 - val_loss: 0.3539 - val_acc: 0.8486 - val_f1: 0.7285\n",
      "Epoch 3/100\n",
      "193943/193943 [==============================] - 83s 426us/step - loss: 0.3114 - acc: 0.8718 - f1: 0.7993 - val_loss: 0.3105 - val_acc: 0.8713 - val_f1: 0.7912\n",
      "Epoch 4/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.2788 - acc: 0.8867 - f1: 0.8237 - val_loss: 0.2989 - val_acc: 0.8795 - val_f1: 0.8123\n",
      "Epoch 5/100\n",
      "193943/193943 [==============================] - 82s 425us/step - loss: 0.2465 - acc: 0.9015 - f1: 0.8473 - val_loss: 0.3113 - val_acc: 0.8761 - val_f1: 0.7953\n",
      "Epoch 6/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.2115 - acc: 0.9173 - f1: 0.8719 - val_loss: 0.3128 - val_acc: 0.8771 - val_f1: 0.8156\n",
      "Epoch 7/100\n",
      "193943/193943 [==============================] - 83s 428us/step - loss: 0.1727 - acc: 0.9342 - f1: 0.8986 - val_loss: 0.3438 - val_acc: 0.8740 - val_f1: 0.8118\n",
      "Epoch 8/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.1320 - acc: 0.9515 - f1: 0.9250 - val_loss: 0.3904 - val_acc: 0.8762 - val_f1: 0.8047\n",
      "Epoch 9/100\n",
      "193943/193943 [==============================] - 83s 426us/step - loss: 0.0951 - acc: 0.9666 - f1: 0.9484 - val_loss: 0.4219 - val_acc: 0.8712 - val_f1: 0.8009\n",
      "Epoch 10/100\n",
      "193943/193943 [==============================] - 83s 429us/step - loss: 0.0647 - acc: 0.9786 - f1: 0.9669 - val_loss: 0.4708 - val_acc: 0.8698 - val_f1: 0.7984\n",
      "Epoch 11/100\n",
      "193943/193943 [==============================] - 83s 429us/step - loss: 0.0449 - acc: 0.9860 - f1: 0.9784 - val_loss: 0.5283 - val_acc: 0.8674 - val_f1: 0.7905\n",
      "Epoch 12/100\n",
      "193943/193943 [==============================] - 83s 429us/step - loss: 0.0330 - acc: 0.9902 - f1: 0.9848 - val_loss: 0.5778 - val_acc: 0.8654 - val_f1: 0.7868\n",
      "Epoch 13/100\n",
      "193943/193943 [==============================] - 83s 428us/step - loss: 0.0263 - acc: 0.9921 - f1: 0.9878 - val_loss: 0.6209 - val_acc: 0.8641 - val_f1: 0.7867\n",
      "Epoch 14/100\n",
      "193943/193943 [==============================] - 83s 429us/step - loss: 0.0230 - acc: 0.9930 - f1: 0.9893 - val_loss: 0.6684 - val_acc: 0.8657 - val_f1: 0.7929\n",
      "Epoch 15/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.0203 - acc: 0.9939 - f1: 0.9906 - val_loss: 0.6729 - val_acc: 0.8639 - val_f1: 0.7899\n",
      "Epoch 16/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.0170 - acc: 0.9951 - f1: 0.9923 - val_loss: 0.7407 - val_acc: 0.8685 - val_f1: 0.7902\n",
      "Epoch 17/100\n",
      "193943/193943 [==============================] - 84s 431us/step - loss: 0.0163 - acc: 0.9950 - f1: 0.9923 - val_loss: 0.7550 - val_acc: 0.8687 - val_f1: 0.7930\n",
      "Epoch 18/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.0162 - acc: 0.9950 - f1: 0.9923 - val_loss: 0.7373 - val_acc: 0.8666 - val_f1: 0.7915\n",
      "Epoch 19/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.0131 - acc: 0.9961 - f1: 0.9940 - val_loss: 0.7592 - val_acc: 0.8635 - val_f1: 0.7887\n",
      "Epoch 20/100\n",
      "193943/193943 [==============================] - 83s 428us/step - loss: 0.0143 - acc: 0.9954 - f1: 0.9929 - val_loss: 0.7912 - val_acc: 0.8675 - val_f1: 0.7944\n",
      "Epoch 21/100\n",
      "193943/193943 [==============================] - 83s 429us/step - loss: 0.0124 - acc: 0.9962 - f1: 0.9941 - val_loss: 0.7944 - val_acc: 0.8625 - val_f1: 0.7890\n",
      "Epoch 22/100\n",
      "193943/193943 [==============================] - 83s 427us/step - loss: 0.0126 - acc: 0.9960 - f1: 0.9939 - val_loss: 0.8306 - val_acc: 0.8654 - val_f1: 0.7956\n",
      "Epoch 23/100\n",
      "193943/193943 [==============================] - 83s 428us/step - loss: 0.0109 - acc: 0.9967 - f1: 0.9949 - val_loss: 0.8592 - val_acc: 0.8680 - val_f1: 0.7947\n",
      "Epoch 24/100\n",
      " 36650/193943 [====>.........................] - ETA: 1:01 - loss: 0.0082 - acc: 0.9977 - f1: 0.9963"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=100,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Flatten\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# model.build()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letter_count = dict(zip(string.ascii_lowercase, [0]*26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{chr(i+96):i for i in range(1,27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenize the sentences\n",
    "# tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, char_level=True)\n",
    "# tokenizer.fit_on_texts(list(train_X_raw))\n",
    "\n",
    "# train_X = tokenizer.texts_to_sequences(train_X_raw)\n",
    "# test_X = tokenizer.texts_to_sequences(test_X_raw)\n",
    "\n",
    "# for sent in train_X_raw:\n",
    "#     s=[]\n",
    "#     for char in sent.lower():\n",
    "#         if char in char_dict.keys():\n",
    "#             s.append(char_dict[char])\n",
    "#     if s!=[]:\n",
    "#         train_X_filt.append(s)\n",
    "#     else:\n",
    "#         print(sent)\n",
    "\n",
    "# ## Get the target values\n",
    "# # train_Y = df_train['target'].values\n",
    "\n",
    "# test_X_filt = []\n",
    "# for sent in test_X_raw:\n",
    "#     s=[]\n",
    "#     for char in sent.lower():\n",
    "#         if char in char_dict.keys():\n",
    "#             s.append(char_dict[char])\n",
    "#     test_X_filt.append(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
