{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation,TimeDistributed\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,BatchNormalization,MaxPooling1D, Convolution1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, RepeatVector, Permute, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google word2vec\n",
    "# from gensim.models import KeyedVectors as wv\n",
    "# word_vectors = wv.load_word2vec_format('./input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "# EMBEDDING_DIM =300\n",
    "\n",
    "#glove\n",
    "word_vectors = {}\n",
    "f = open('./input/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    word_vectors[word] = coefs\n",
    "f.close()\n",
    "EMBEDDING_DIM =300\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1044897, 3)\n",
      "Test shape :  (261225, 3)\n",
      "Train shape :  (387192, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133472 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv(\"./input/train.csv\")\n",
    "# df_test = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "df = pd.read_csv(\"./input/train.csv\")\n",
    "df_train, df_test = train_test_split(df, test_size=0.2,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)\n",
    "\n",
    "df_train_pos = df_train[df_train['target']==1]\n",
    "df_train_neg = df_train[df_train['target']==0].sample(len(df_train_pos)*5,random_state=1)\n",
    "df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "df_train = df_train.sample(frac=1,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=150\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df_train['question_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['question_text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "train_Y = df_train['target']\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_test['question_text'])\n",
    "test_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "test_Y = df_test['target']\n",
    "# labels = to_categorical(np.asarray(labels))\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "# indices = np.arange(data.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# data = data[indices]\n",
    "# labels = labels[indices]\n",
    "# nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "# x_train = data[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "# x_val = data[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What can make you effective teacher?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.iloc[4]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.65645984421165\n",
      "62.0\n",
      "41.84467927436718\n",
      "1017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.15713e+05, 6.37790e+04, 7.69500e+03, 3.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00]),\n",
       " array([1.000e+00, 1.026e+02, 2.042e+02, 3.058e+02, 4.074e+02, 5.090e+02,\n",
       "        6.106e+02, 7.122e+02, 8.138e+02, 9.154e+02, 1.017e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for sent in df_train['question_text']:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "#     if max(sent)>50:\n",
    "#         print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "plt.hist(lengths,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for google word2vec\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        word_vector = word_vectors[word]\n",
    "#     if word_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387192, 150)\n",
      "(387192,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_X_raw[0])\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 150, 300)     40041900    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 148, 10)      9010        embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 143, 10)      24010       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 74, 10)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 71, 10)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 740)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 710)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1450)         0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1450)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 50)           72550       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            51          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 40,147,521\n",
      "Trainable params: 105,621\n",
      "Non-trainable params: 40,041,900\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##model definition\n",
    "# model = Sequential()\n",
    "dropout_prob = [0.2,0.2]\n",
    "hidden_dims = 50\n",
    "filter_sizes  = (3,8)\n",
    "num_filters = 10\n",
    "\n",
    "input_shape = (MAX_SEQUENCE_LENGTH,)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)(model_input)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348472 samples, validate on 38720 samples\n",
      "Epoch 1/10\n",
      "348472/348472 [==============================] - 19s 54us/step - loss: 0.2287 - acc: 0.9051 - val_loss: 0.1999 - val_acc: 0.9184\n",
      "Epoch 2/10\n",
      "171000/348472 [=============>................] - ETA: 6s - loss: 0.2033 - acc: 0.9169"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=10,batch_size=500,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 31s 119us/step\n",
      "0.6395928956296147\n"
     ]
    }
   ],
   "source": [
    "preds= model.predict_classes(test_X,verbose=1,batch_size=5000)\n",
    "print(metrics.f1_score(test_Y, preds))\n",
    "# pred_cnn_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold -0.2 is 0.5\n",
      "F1 score at threshold -0.15 is 0.5\n",
      "F1 score at threshold -0.1 is 0.5\n",
      "F1 score at threshold -0.05 is 0.5\n",
      "F1 score at threshold -0.0 is 0.5006551699569726\n",
      "F1 score at threshold 0.05 is 0.9538913433701808\n",
      "F1 score at threshold 0.1 is 0.9588053741119749\n",
      "F1 score at threshold 0.15 is 0.9608015640273705\n",
      "F1 score at threshold 0.2 is 0.9622097119018885\n",
      "F1 score at threshold 0.25 is 0.9630757144260041\n",
      "F1 score at threshold 0.3 is 0.9636065150425176\n",
      "F1 score at threshold 0.35 is 0.9639653505882643\n",
      "F1 score at threshold 0.4 is 0.9641520716588683\n",
      "F1 score at threshold 0.45 is 0.964307977164018\n",
      "F1 score at threshold 0.5 is 0.9644417258274791\n",
      "F1 score at threshold 0.55 is 0.9646491200940216\n",
      "F1 score at threshold 0.6 is 0.9645400611848054\n",
      "F1 score at threshold 0.65 is 0.964271098158368\n",
      "F1 score at threshold 0.7 is 0.9639306803434937\n",
      "F1 score at threshold 0.75 is 0.9634884906669319\n",
      "F1 score at threshold 0.8 is 0.9628457710203242\n",
      "F1 score at threshold 0.85 is 0.9619818616466829\n",
      "F1 score at threshold 0.9 is 0.9603125410867565\n",
      "F1 score at threshold 0.95 is 0.9561179094884624\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(-0.20, 1, 0.05):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(train_Y, (preds>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 9s 163us/step\n",
      "[7259]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(test_X,verbose=1)\n",
    "# print(metrics.f1_score(train_Y,preds))\n",
    "print(sum(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out[\"qid\"] = df_test['qid']\n",
    "df_out[\"predictions\"] = preds\n",
    "df_out.to_csv(\"sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81037], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
