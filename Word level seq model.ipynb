{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,BatchNormalization\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, RepeatVector, Permute, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google word2vec\n",
    "from gensim.models import KeyedVectors as wv\n",
    "word_vectors = wv.load_word2vec_format('./input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "EMBEDDING_DIM =300\n",
    "\n",
    "##glove\n",
    "# embeddings_index = {}\n",
    "# f = open(os.path.join(GLOVE_DIR, './input/embeddings/glove.840B.300d/glove.840B.300d.txt'))\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "# EMBEDDING_DIM =300\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n",
      "Train shape :  (484860, 3)\n",
      "Found 152399 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./input/train.csv\")\n",
    "df_test = pd.read_csv(\"./input/test.csv\")\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)\n",
    "\n",
    "df_train_pos = df_train[df_train['target']==1]\n",
    "df_train_neg = df_train[df_train['target']==0].sample(len(df_train_pos)*5,random_state=1)\n",
    "df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "df_train = df_train.sample(frac=1,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=150\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df_train['question_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['question_text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "train_Y = df_train['target']\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_test['question_text'])\n",
    "test_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "# test_Y = df_test['target']\n",
    "# labels = to_categorical(np.asarray(labels))\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "# indices = np.arange(data.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# data = data[indices]\n",
    "# labels = labels[indices]\n",
    "# nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "# x_train = data[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "# x_val = data[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whats the percentage of people who actually live up to their marriage vows, including the \"til death do us part\" part?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.iloc[4]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.6223714061791\n",
      "62.0\n",
      "41.76537274429307\n",
      "1017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.9506e+05, 8.0336e+04, 9.4590e+03, 3.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       " array([1.000e+00, 1.026e+02, 2.042e+02, 3.058e+02, 4.074e+02, 5.090e+02,\n",
       "        6.106e+02, 7.122e+02, 8.138e+02, 9.154e+02, 1.017e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for sent in df_train['question_text']:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "#     if max(sent)>50:\n",
    "#         print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "plt.hist(lengths,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for google word2vec\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        word_vector = word_vectors[word]\n",
    "#     if word_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484860, 150)\n",
      "(484860,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_X_raw[0])\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 150, 300)          45720000  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 150, 200)          321600    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               3000100   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 49,041,801\n",
      "Trainable params: 3,321,801\n",
      "Non-trainable params: 45,720,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "\n",
    "\n",
    "# model.add(CuDNNLSTM(75, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Bidirectional(CuDNNLSTM(100, return_sequences=True), input_shape=(train_X.shape[1], EMBEDDING_DIM)))\n",
    "# model.add(Bidirectional(CuDNNLSTM(100, return_sequences=False)))#, input_shape=(train_X.shape[1], EMBEDDING_DIM)))\n",
    "# model.add(Attention(MAX_SEQUENCE_LENGTH))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 387888 samples, validate on 96972 samples\n",
      "Epoch 1/50\n",
      "387888/387888 [==============================] - 64s 165us/step - loss: 0.2134 - acc: 0.9127 - f1: 0.7240 - val_loss: 0.1913 - val_acc: 0.9232 - val_f1: 0.7638\n",
      "Epoch 2/50\n",
      "387888/387888 [==============================] - 64s 165us/step - loss: 0.1875 - acc: 0.9242 - f1: 0.7666 - val_loss: 0.1822 - val_acc: 0.9282 - val_f1: 0.7678\n",
      "Epoch 3/50\n",
      "387888/387888 [==============================] - 65s 166us/step - loss: 0.1746 - acc: 0.9302 - f1: 0.7860 - val_loss: 0.1767 - val_acc: 0.9298 - val_f1: 0.7844\n",
      "Epoch 4/50\n",
      "387888/387888 [==============================] - 67s 172us/step - loss: 0.1631 - acc: 0.9348 - f1: 0.8011 - val_loss: 0.1756 - val_acc: 0.9307 - val_f1: 0.7806\n",
      "Epoch 5/50\n",
      "387888/387888 [==============================] - 67s 172us/step - loss: 0.1503 - acc: 0.9403 - f1: 0.8185 - val_loss: 0.1806 - val_acc: 0.9289 - val_f1: 0.7758\n",
      "Epoch 6/50\n",
      "387888/387888 [==============================] - 66s 171us/step - loss: 0.1357 - acc: 0.9464 - f1: 0.8375 - val_loss: 0.1863 - val_acc: 0.9297 - val_f1: 0.7842\n",
      "Epoch 7/50\n",
      "387888/387888 [==============================] - 66s 171us/step - loss: 0.1192 - acc: 0.9533 - f1: 0.8588 - val_loss: 0.2029 - val_acc: 0.9276 - val_f1: 0.7679\n",
      "Epoch 8/50\n",
      "387888/387888 [==============================] - 66s 171us/step - loss: 0.1008 - acc: 0.9606 - f1: 0.8814 - val_loss: 0.2166 - val_acc: 0.9246 - val_f1: 0.7710\n",
      "Epoch 9/50\n",
      "387888/387888 [==============================] - 66s 171us/step - loss: 0.0830 - acc: 0.9681 - f1: 0.9039 - val_loss: 0.2545 - val_acc: 0.9252 - val_f1: 0.7663\n",
      "Epoch 10/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0660 - acc: 0.9751 - f1: 0.9253 - val_loss: 0.2817 - val_acc: 0.9234 - val_f1: 0.7619\n",
      "Epoch 11/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0511 - acc: 0.9812 - f1: 0.9435 - val_loss: 0.3442 - val_acc: 0.9199 - val_f1: 0.7366\n",
      "Epoch 12/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0405 - acc: 0.9852 - f1: 0.9558 - val_loss: 0.3621 - val_acc: 0.9180 - val_f1: 0.7441\n",
      "Epoch 13/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0317 - acc: 0.9889 - f1: 0.9667 - val_loss: 0.3864 - val_acc: 0.9184 - val_f1: 0.7482\n",
      "Epoch 14/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0253 - acc: 0.9911 - f1: 0.9733 - val_loss: 0.4355 - val_acc: 0.9163 - val_f1: 0.7384\n",
      "Epoch 15/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0209 - acc: 0.9930 - f1: 0.9788 - val_loss: 0.4486 - val_acc: 0.9164 - val_f1: 0.7442\n",
      "Epoch 16/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0171 - acc: 0.9943 - f1: 0.9828 - val_loss: 0.4914 - val_acc: 0.9175 - val_f1: 0.7444\n",
      "Epoch 17/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0145 - acc: 0.9951 - f1: 0.9854 - val_loss: 0.5087 - val_acc: 0.9182 - val_f1: 0.7497\n",
      "Epoch 18/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0133 - acc: 0.9955 - f1: 0.9864 - val_loss: 0.5389 - val_acc: 0.9174 - val_f1: 0.7504\n",
      "Epoch 19/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0111 - acc: 0.9965 - f1: 0.9895 - val_loss: 0.5490 - val_acc: 0.9183 - val_f1: 0.7461\n",
      "Epoch 20/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0112 - acc: 0.9963 - f1: 0.9888 - val_loss: 0.5543 - val_acc: 0.9171 - val_f1: 0.7455\n",
      "Epoch 21/50\n",
      "387888/387888 [==============================] - 66s 169us/step - loss: 0.0099 - acc: 0.9967 - f1: 0.9902 - val_loss: 0.5520 - val_acc: 0.9166 - val_f1: 0.7463\n",
      "Epoch 22/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0089 - acc: 0.9971 - f1: 0.9913 - val_loss: 0.5865 - val_acc: 0.9181 - val_f1: 0.7373\n",
      "Epoch 23/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0078 - acc: 0.9975 - f1: 0.9924 - val_loss: 0.6086 - val_acc: 0.9174 - val_f1: 0.7364\n",
      "Epoch 24/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0089 - acc: 0.9970 - f1: 0.9911 - val_loss: 0.6006 - val_acc: 0.9189 - val_f1: 0.7453\n",
      "Epoch 25/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0079 - acc: 0.9975 - f1: 0.9924 - val_loss: 0.6162 - val_acc: 0.9169 - val_f1: 0.7455\n",
      "Epoch 26/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0064 - acc: 0.9981 - f1: 0.9942 - val_loss: 0.6337 - val_acc: 0.9197 - val_f1: 0.7473\n",
      "Epoch 27/50\n",
      "387888/387888 [==============================] - 65s 169us/step - loss: 0.0076 - acc: 0.9975 - f1: 0.9924 - val_loss: 0.6196 - val_acc: 0.9158 - val_f1: 0.7447\n",
      "Epoch 28/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0072 - acc: 0.9977 - f1: 0.9932 - val_loss: 0.6187 - val_acc: 0.9162 - val_f1: 0.7388\n",
      "Epoch 29/50\n",
      "387888/387888 [==============================] - 65s 169us/step - loss: 0.0064 - acc: 0.9980 - f1: 0.9940 - val_loss: 0.6046 - val_acc: 0.9170 - val_f1: 0.7439\n",
      "Epoch 30/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0064 - acc: 0.9980 - f1: 0.9939 - val_loss: 0.6520 - val_acc: 0.9162 - val_f1: 0.7442\n",
      "Epoch 31/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0065 - acc: 0.9978 - f1: 0.9935 - val_loss: 0.6558 - val_acc: 0.9156 - val_f1: 0.7511\n",
      "Epoch 32/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0067 - acc: 0.9978 - f1: 0.9935 - val_loss: 0.6497 - val_acc: 0.9172 - val_f1: 0.7417\n",
      "Epoch 33/50\n",
      "387888/387888 [==============================] - 65s 169us/step - loss: 0.0049 - acc: 0.9985 - f1: 0.9954 - val_loss: 0.6715 - val_acc: 0.9197 - val_f1: 0.7482\n",
      "Epoch 34/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0048 - acc: 0.9985 - f1: 0.9954 - val_loss: 0.6681 - val_acc: 0.9189 - val_f1: 0.7461\n",
      "Epoch 35/50\n",
      "387888/387888 [==============================] - 65s 168us/step - loss: 0.0057 - acc: 0.9982 - f1: 0.9946 - val_loss: 0.6632 - val_acc: 0.9180 - val_f1: 0.7482\n",
      "Epoch 36/50\n",
      "387888/387888 [==============================] - 67s 172us/step - loss: 0.0054 - acc: 0.9984 - f1: 0.9950 - val_loss: 0.6710 - val_acc: 0.9186 - val_f1: 0.7438\n",
      "Epoch 37/50\n",
      "387888/387888 [==============================] - 67s 172us/step - loss: 0.0053 - acc: 0.9983 - f1: 0.9950 - val_loss: 0.6790 - val_acc: 0.9178 - val_f1: 0.7459\n",
      "Epoch 38/50\n",
      "387888/387888 [==============================] - 65s 167us/step - loss: 0.0043 - acc: 0.9986 - f1: 0.9957 - val_loss: 0.7136 - val_acc: 0.9165 - val_f1: 0.7324\n",
      "Epoch 39/50\n",
      "387888/387888 [==============================] - 64s 166us/step - loss: 0.0050 - acc: 0.9984 - f1: 0.9951 - val_loss: 0.7154 - val_acc: 0.9139 - val_f1: 0.7424\n",
      "Epoch 40/50\n",
      "387888/387888 [==============================] - 64s 166us/step - loss: 0.0052 - acc: 0.9983 - f1: 0.9949 - val_loss: 0.6879 - val_acc: 0.9146 - val_f1: 0.7456\n",
      "Epoch 41/50\n",
      "387888/387888 [==============================] - 64s 166us/step - loss: 0.0041 - acc: 0.9987 - f1: 0.9960 - val_loss: 0.6962 - val_acc: 0.9160 - val_f1: 0.7444\n",
      "Epoch 42/50\n",
      "387888/387888 [==============================] - 64s 166us/step - loss: 0.0039 - acc: 0.9988 - f1: 0.9963 - val_loss: 0.6978 - val_acc: 0.9179 - val_f1: 0.7483\n",
      "Epoch 43/50\n",
      "387888/387888 [==============================] - 65s 167us/step - loss: 0.0044 - acc: 0.9986 - f1: 0.9956 - val_loss: 0.6950 - val_acc: 0.9156 - val_f1: 0.7410\n",
      "Epoch 44/50\n",
      "387888/387888 [==============================] - 69s 178us/step - loss: 0.0048 - acc: 0.9984 - f1: 0.9951 - val_loss: 0.7092 - val_acc: 0.9186 - val_f1: 0.7503\n",
      "Epoch 45/50\n",
      "387888/387888 [==============================] - 68s 175us/step - loss: 0.0039 - acc: 0.9987 - f1: 0.9962 - val_loss: 0.6953 - val_acc: 0.9177 - val_f1: 0.7420\n",
      "Epoch 46/50\n",
      "387888/387888 [==============================] - 67s 172us/step - loss: 0.0040 - acc: 0.9988 - f1: 0.9963 - val_loss: 0.6996 - val_acc: 0.9178 - val_f1: 0.7450\n",
      "Epoch 47/50\n",
      "387888/387888 [==============================] - 66s 170us/step - loss: 0.0033 - acc: 0.9990 - f1: 0.9970 - val_loss: 0.7251 - val_acc: 0.9178 - val_f1: 0.7534\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387888/387888 [==============================] - 65s 169us/step - loss: 0.0050 - acc: 0.9984 - f1: 0.9952 - val_loss: 0.7127 - val_acc: 0.9166 - val_f1: 0.7452\n",
      "Epoch 49/50\n",
      "374500/387888 [===========================>..] - ETA: 2s - loss: 0.0039 - acc: 0.9987 - f1: 0.9961"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fdeb697d8c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=50,batch_size=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242430/242430 [==============================] - 40s 165us/step\n"
     ]
    }
   ],
   "source": [
    "preds= model.predict(train_X,verbose=1)\n",
    "# pred_cnn_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold -0.2 is 0.5\n",
      "F1 score at threshold -0.15 is 0.5\n",
      "F1 score at threshold -0.1 is 0.5\n",
      "F1 score at threshold -0.05 is 0.5\n",
      "F1 score at threshold -0.0 is 0.5006551699569726\n",
      "F1 score at threshold 0.05 is 0.9538913433701808\n",
      "F1 score at threshold 0.1 is 0.9588053741119749\n",
      "F1 score at threshold 0.15 is 0.9608015640273705\n",
      "F1 score at threshold 0.2 is 0.9622097119018885\n",
      "F1 score at threshold 0.25 is 0.9630757144260041\n",
      "F1 score at threshold 0.3 is 0.9636065150425176\n",
      "F1 score at threshold 0.35 is 0.9639653505882643\n",
      "F1 score at threshold 0.4 is 0.9641520716588683\n",
      "F1 score at threshold 0.45 is 0.964307977164018\n",
      "F1 score at threshold 0.5 is 0.9644417258274791\n",
      "F1 score at threshold 0.55 is 0.9646491200940216\n",
      "F1 score at threshold 0.6 is 0.9645400611848054\n",
      "F1 score at threshold 0.65 is 0.964271098158368\n",
      "F1 score at threshold 0.7 is 0.9639306803434937\n",
      "F1 score at threshold 0.75 is 0.9634884906669319\n",
      "F1 score at threshold 0.8 is 0.9628457710203242\n",
      "F1 score at threshold 0.85 is 0.9619818616466829\n",
      "F1 score at threshold 0.9 is 0.9603125410867565\n",
      "F1 score at threshold 0.95 is 0.9561179094884624\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(-0.20, 1, 0.05):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(train_Y, (preds>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 9s 163us/step\n",
      "[7259]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(test_X,verbose=1)\n",
    "# print(metrics.f1_score(train_Y,preds))\n",
    "print(sum(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out[\"qid\"] = df_test['qid']\n",
    "df_out[\"predictions\"] = preds\n",
    "df_out.to_csv(\"sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81037], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 150, 300)          30870600  \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 150, 280)          495040    \n",
      "=================================================================\n",
      "Total params: 31,365,640\n",
      "Trainable params: 495,040\n",
      "Non-trainable params: 30,870,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_28 (RepeatVect (None, 150, 1)            0         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=150, units=1)`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-62b9190e6e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# model.add(Merge([model1, model2], 'mul'))  # Multiply each element with corresponding weight a[i][j][k] * b[i][j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributedMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Flatten\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# model.build()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letter_count = dict(zip(string.ascii_lowercase, [0]*26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{chr(i+96):i for i in range(1,27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
