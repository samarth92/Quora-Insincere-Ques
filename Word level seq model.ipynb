{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation,TimeDistributed\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,BatchNormalization\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D, RepeatVector, Permute, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google word2vec\n",
    "# from gensim.models import KeyedVectors as wv\n",
    "# word_vectors = wv.load_word2vec_format('./input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "# EMBEDDING_DIM =300\n",
    "\n",
    "#glove\n",
    "word_vectors = {}\n",
    "f = open('./input/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ''.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    word_vectors[word] = coefs\n",
    "f.close()\n",
    "EMBEDDING_DIM =300\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1044897, 3)\n",
      "Test shape :  (261225, 3)\n",
      "Train shape :  (387192, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 133472 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# df_train = pd.read_csv(\"./input/train.csv\")\n",
    "# df_test = pd.read_csv(\"./input/test.csv\")\n",
    "\n",
    "df = pd.read_csv(\"./input/train.csv\")\n",
    "df_train, df_test = train_test_split(df, test_size=0.2,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)\n",
    "\n",
    "df_train_pos = df_train[df_train['target']==1]\n",
    "df_train_neg = df_train[df_train['target']==0].sample(len(df_train_pos)*5,random_state=1)\n",
    "df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "df_train = df_train.sample(frac=1,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=150\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df_train['question_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['question_text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "train_Y = df_train['target']\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_test['question_text'])\n",
    "test_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "test_Y = df_test['target']\n",
    "# labels = to_categorical(np.asarray(labels))\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "# indices = np.arange(data.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# data = data[indices]\n",
    "# labels = labels[indices]\n",
    "# nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "# x_train = data[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "# x_val = data[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What can make you effective teacher?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.iloc[4]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.65645984421165\n",
      "62.0\n",
      "41.84467927436718\n",
      "1017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.15713e+05, 6.37790e+04, 7.69500e+03, 3.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00]),\n",
       " array([1.000e+00, 1.026e+02, 2.042e+02, 3.058e+02, 4.074e+02, 5.090e+02,\n",
       "        6.106e+02, 7.122e+02, 8.138e+02, 9.154e+02, 1.017e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for sent in df_train['question_text']:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "#     if max(sent)>50:\n",
    "#         print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "plt.hist(lengths,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for google word2vec\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        word_vector = word_vectors[word]\n",
    "#     if word_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(387192, 150)\n",
      "(387192,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_X_raw[0])\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 150, 300)          40041900  \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 150, 120)          173760    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 150, 120)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 150, 40)           22720     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               600100    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,838,581\n",
      "Trainable params: 796,681\n",
      "Non-trainable params: 40,041,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "\n",
    "\n",
    "# model.add(CuDNNLSTM(75, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Bidirectional(CuDNNLSTM(60, return_sequences=True), input_shape=(train_X.shape[1], EMBEDDING_DIM)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Bidirectional(CuDNNLSTM(20, return_sequences=True)))#, input_shape=(train_X.shape[1], EMBEDDING_DIM)))\n",
    "# model.add(Attention(MAX_SEQUENCE_LENGTH))\n",
    "model.add(Flatten())\n",
    "# model.add(TimeDistributed(Dense(100,activation='relu')))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348472 samples, validate on 38720 samples\n",
      "Epoch 1/50\n",
      "348472/348472 [==============================] - 53s 153us/step - loss: 0.0997 - acc: 0.9604 - f1: 0.8827 - val_loss: 0.2113 - val_acc: 0.9286 - val_f1: 0.7866\n",
      "Epoch 2/50\n",
      "348472/348472 [==============================] - 54s 154us/step - loss: 0.0918 - acc: 0.9637 - f1: 0.8926 - val_loss: 0.2322 - val_acc: 0.9285 - val_f1: 0.7821\n",
      "Epoch 3/50\n",
      "348472/348472 [==============================] - 54s 155us/step - loss: 0.0844 - acc: 0.9667 - f1: 0.9012 - val_loss: 0.2345 - val_acc: 0.9244 - val_f1: 0.7717\n",
      "Epoch 4/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0778 - acc: 0.9693 - f1: 0.9090 - val_loss: 0.2667 - val_acc: 0.9262 - val_f1: 0.7722\n",
      "Epoch 5/50\n",
      "348472/348472 [==============================] - 56s 159us/step - loss: 0.0722 - acc: 0.9716 - f1: 0.9160 - val_loss: 0.2979 - val_acc: 0.9290 - val_f1: 0.7747\n",
      "Epoch 6/50\n",
      "348472/348472 [==============================] - 56s 159us/step - loss: 0.0661 - acc: 0.9743 - f1: 0.9237 - val_loss: 0.3021 - val_acc: 0.9233 - val_f1: 0.7604\n",
      "Epoch 7/50\n",
      "348472/348472 [==============================] - 56s 160us/step - loss: 0.0613 - acc: 0.9758 - f1: 0.9282 - val_loss: 0.3122 - val_acc: 0.9236 - val_f1: 0.7717\n",
      "Epoch 8/50\n",
      "348472/348472 [==============================] - 55s 158us/step - loss: 0.0577 - acc: 0.9776 - f1: 0.9335 - val_loss: 0.3250 - val_acc: 0.9243 - val_f1: 0.7665\n",
      "Epoch 9/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0529 - acc: 0.9795 - f1: 0.9390 - val_loss: 0.3659 - val_acc: 0.9243 - val_f1: 0.7707\n",
      "Epoch 10/50\n",
      "348472/348472 [==============================] - 55s 158us/step - loss: 0.0492 - acc: 0.9811 - f1: 0.9438 - val_loss: 0.3659 - val_acc: 0.9234 - val_f1: 0.7713\n",
      "Epoch 11/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0465 - acc: 0.9820 - f1: 0.9464 - val_loss: 0.3590 - val_acc: 0.9220 - val_f1: 0.7676\n",
      "Epoch 12/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0429 - acc: 0.9837 - f1: 0.9513 - val_loss: 0.4064 - val_acc: 0.9220 - val_f1: 0.7602\n",
      "Epoch 13/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0404 - acc: 0.9846 - f1: 0.9540 - val_loss: 0.3818 - val_acc: 0.9225 - val_f1: 0.7697\n",
      "Epoch 14/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0390 - acc: 0.9851 - f1: 0.9553 - val_loss: 0.4078 - val_acc: 0.9201 - val_f1: 0.7563\n",
      "Epoch 15/50\n",
      "348472/348472 [==============================] - 55s 156us/step - loss: 0.0356 - acc: 0.9865 - f1: 0.9599 - val_loss: 0.4327 - val_acc: 0.9175 - val_f1: 0.7567\n",
      "Epoch 16/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0340 - acc: 0.9872 - f1: 0.9616 - val_loss: 0.4718 - val_acc: 0.9207 - val_f1: 0.7540\n",
      "Epoch 17/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0326 - acc: 0.9877 - f1: 0.9633 - val_loss: 0.4629 - val_acc: 0.9199 - val_f1: 0.7461\n",
      "Epoch 18/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0304 - acc: 0.9886 - f1: 0.9657 - val_loss: 0.4732 - val_acc: 0.9209 - val_f1: 0.7614\n",
      "Epoch 19/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0290 - acc: 0.9891 - f1: 0.9672 - val_loss: 0.4867 - val_acc: 0.9204 - val_f1: 0.7581\n",
      "Epoch 20/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0272 - acc: 0.9898 - f1: 0.9694 - val_loss: 0.5157 - val_acc: 0.9210 - val_f1: 0.7557\n",
      "Epoch 21/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0255 - acc: 0.9905 - f1: 0.9717 - val_loss: 0.4910 - val_acc: 0.9171 - val_f1: 0.7541\n",
      "Epoch 22/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0248 - acc: 0.9906 - f1: 0.9718 - val_loss: 0.5220 - val_acc: 0.9222 - val_f1: 0.7607\n",
      "Epoch 23/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0231 - acc: 0.9915 - f1: 0.9745 - val_loss: 0.4975 - val_acc: 0.9177 - val_f1: 0.7525\n",
      "Epoch 24/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0233 - acc: 0.9912 - f1: 0.9733 - val_loss: 0.5536 - val_acc: 0.9183 - val_f1: 0.7593\n",
      "Epoch 25/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0217 - acc: 0.9920 - f1: 0.9760 - val_loss: 0.5252 - val_acc: 0.9205 - val_f1: 0.7528\n",
      "Epoch 26/50\n",
      "348472/348472 [==============================] - 55s 156us/step - loss: 0.0209 - acc: 0.9925 - f1: 0.9774 - val_loss: 0.5597 - val_acc: 0.9202 - val_f1: 0.7563\n",
      "Epoch 27/50\n",
      "348472/348472 [==============================] - 55s 156us/step - loss: 0.0200 - acc: 0.9926 - f1: 0.9779 - val_loss: 0.5561 - val_acc: 0.9200 - val_f1: 0.7551\n",
      "Epoch 28/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0198 - acc: 0.9927 - f1: 0.9781 - val_loss: 0.5297 - val_acc: 0.9195 - val_f1: 0.7527\n",
      "Epoch 29/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0173 - acc: 0.9938 - f1: 0.9815 - val_loss: 0.5695 - val_acc: 0.9211 - val_f1: 0.7553\n",
      "Epoch 30/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0185 - acc: 0.9932 - f1: 0.9795 - val_loss: 0.5708 - val_acc: 0.9210 - val_f1: 0.7525\n",
      "Epoch 31/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0177 - acc: 0.9936 - f1: 0.9806 - val_loss: 0.5413 - val_acc: 0.9183 - val_f1: 0.7544\n",
      "Epoch 32/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0167 - acc: 0.9939 - f1: 0.9816 - val_loss: 0.5941 - val_acc: 0.9194 - val_f1: 0.7541\n",
      "Epoch 33/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0162 - acc: 0.9944 - f1: 0.9830 - val_loss: 0.5728 - val_acc: 0.9190 - val_f1: 0.7549\n",
      "Epoch 34/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0161 - acc: 0.9941 - f1: 0.9822 - val_loss: 0.5775 - val_acc: 0.9187 - val_f1: 0.7484\n",
      "Epoch 35/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0145 - acc: 0.9948 - f1: 0.9845 - val_loss: 0.5778 - val_acc: 0.9186 - val_f1: 0.7535\n",
      "Epoch 36/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0140 - acc: 0.9951 - f1: 0.9852 - val_loss: 0.6124 - val_acc: 0.9158 - val_f1: 0.7524\n",
      "Epoch 37/50\n",
      "348472/348472 [==============================] - 55s 156us/step - loss: 0.0143 - acc: 0.9949 - f1: 0.9848 - val_loss: 0.5926 - val_acc: 0.9186 - val_f1: 0.7472\n",
      "Epoch 38/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0132 - acc: 0.9952 - f1: 0.9856 - val_loss: 0.6198 - val_acc: 0.9178 - val_f1: 0.7527\n",
      "Epoch 39/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0136 - acc: 0.9952 - f1: 0.9855 - val_loss: 0.5819 - val_acc: 0.9186 - val_f1: 0.7522\n",
      "Epoch 40/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0134 - acc: 0.9951 - f1: 0.9853 - val_loss: 0.6192 - val_acc: 0.9202 - val_f1: 0.7519\n",
      "Epoch 41/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0130 - acc: 0.9953 - f1: 0.9859 - val_loss: 0.6142 - val_acc: 0.9174 - val_f1: 0.7502\n",
      "Epoch 42/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0121 - acc: 0.9958 - f1: 0.9874 - val_loss: 0.5996 - val_acc: 0.9192 - val_f1: 0.7519\n",
      "Epoch 43/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0119 - acc: 0.9958 - f1: 0.9873 - val_loss: 0.5776 - val_acc: 0.9181 - val_f1: 0.7446\n",
      "Epoch 44/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0125 - acc: 0.9957 - f1: 0.9869 - val_loss: 0.6154 - val_acc: 0.9205 - val_f1: 0.7491\n",
      "Epoch 45/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0114 - acc: 0.9959 - f1: 0.9877 - val_loss: 0.6168 - val_acc: 0.9179 - val_f1: 0.7495\n",
      "Epoch 46/50\n",
      "348472/348472 [==============================] - 55s 157us/step - loss: 0.0114 - acc: 0.9960 - f1: 0.9879 - val_loss: 0.6013 - val_acc: 0.9190 - val_f1: 0.7509\n",
      "Epoch 47/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0110 - acc: 0.9962 - f1: 0.9885 - val_loss: 0.6019 - val_acc: 0.9197 - val_f1: 0.7522\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0105 - acc: 0.9964 - f1: 0.9891 - val_loss: 0.6258 - val_acc: 0.9177 - val_f1: 0.7500\n",
      "Epoch 49/50\n",
      "348472/348472 [==============================] - 54s 155us/step - loss: 0.0103 - acc: 0.9964 - f1: 0.9890 - val_loss: 0.6363 - val_acc: 0.9182 - val_f1: 0.7526\n",
      "Epoch 50/50\n",
      "348472/348472 [==============================] - 54s 156us/step - loss: 0.0106 - acc: 0.9963 - f1: 0.9888 - val_loss: 0.6003 - val_acc: 0.9192 - val_f1: 0.7481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4e35293a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=50,batch_size=500,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261225/261225 [==============================] - 14s 53us/step\n",
      "0.6063827055893605\n"
     ]
    }
   ],
   "source": [
    "preds= model.predict_classes(test_X,verbose=1,batch_size=1000)\n",
    "print(metrics.f1_score(test_Y, preds))\n",
    "# pred_cnn_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold -0.2 is 0.5\n",
      "F1 score at threshold -0.15 is 0.5\n",
      "F1 score at threshold -0.1 is 0.5\n",
      "F1 score at threshold -0.05 is 0.5\n",
      "F1 score at threshold -0.0 is 0.5006551699569726\n",
      "F1 score at threshold 0.05 is 0.9538913433701808\n",
      "F1 score at threshold 0.1 is 0.9588053741119749\n",
      "F1 score at threshold 0.15 is 0.9608015640273705\n",
      "F1 score at threshold 0.2 is 0.9622097119018885\n",
      "F1 score at threshold 0.25 is 0.9630757144260041\n",
      "F1 score at threshold 0.3 is 0.9636065150425176\n",
      "F1 score at threshold 0.35 is 0.9639653505882643\n",
      "F1 score at threshold 0.4 is 0.9641520716588683\n",
      "F1 score at threshold 0.45 is 0.964307977164018\n",
      "F1 score at threshold 0.5 is 0.9644417258274791\n",
      "F1 score at threshold 0.55 is 0.9646491200940216\n",
      "F1 score at threshold 0.6 is 0.9645400611848054\n",
      "F1 score at threshold 0.65 is 0.964271098158368\n",
      "F1 score at threshold 0.7 is 0.9639306803434937\n",
      "F1 score at threshold 0.75 is 0.9634884906669319\n",
      "F1 score at threshold 0.8 is 0.9628457710203242\n",
      "F1 score at threshold 0.85 is 0.9619818616466829\n",
      "F1 score at threshold 0.9 is 0.9603125410867565\n",
      "F1 score at threshold 0.95 is 0.9561179094884624\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(-0.20, 1, 0.05):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(train_Y, (preds>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56370/56370 [==============================] - 9s 163us/step\n",
      "[7259]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(test_X,verbose=1)\n",
    "# print(metrics.f1_score(train_Y,preds))\n",
    "print(sum(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out[\"qid\"] = df_test['qid']\n",
    "df_out[\"predictions\"] = preds\n",
    "df_out.to_csv(\"sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81037], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Keras Layer that implements an Attention mechanism for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
    "        # Input shape\n",
    "            3D tensor with shape: `(samples, steps, features)`.\n",
    "        # Output shape\n",
    "            2D tensor with shape: `(samples, features)`.\n",
    "        :param kwargs:\n",
    "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "        The dimensions are inferred based on the output shape of the RNN.\n",
    "        Example:\n",
    "            model.add(LSTM(64, return_sequences=True))\n",
    "            model.add(Attention())\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        #self.init = initializations.get('glorot_uniform')\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # eij = K.dot(x, self.W) TF backend doesn't support it\n",
    "\n",
    "        # features_dim = self.W.shape[0]\n",
    "        # step_dim = x._keras_shape[1]\n",
    "\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "    #print weigthted_input.shape\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return input_shape[0], input_shape[-1]\n",
    "        return input_shape[0],  self.features_dim\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 150, 300)          30870600  \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 150, 280)          495040    \n",
      "=================================================================\n",
      "Total params: 31,365,640\n",
      "Trainable params: 495,040\n",
      "Non-trainable params: 30,870,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_28 (RepeatVect (None, 150, 1)            0         \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/anaconda3/envs/tensorflow36/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=150, units=1)`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-62b9190e6e06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# model.add(Merge([model1, model2], 'mul'))  # Multiply each element with corresponding weight a[i][j][k] * b[i][j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeDistributedMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Flatten\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# model.build()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letter_count = dict(zip(string.ascii_lowercase, [0]*26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{chr(i+96):i for i in range(1,27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
