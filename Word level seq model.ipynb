{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import concatenate\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google word2vec\n",
    "from gensim.models import KeyedVectors as wv\n",
    "word_vectors = wv.load_word2vec_format('./input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "EMBEDDING_DIM =300\n",
    "\n",
    "##glove\n",
    "# embeddings_index = {}\n",
    "# f = open(os.path.join(GLOVE_DIR, './input/embeddings/glove.840B.300d/glove.840B.300d.txt'))\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "# EMBEDDING_DIM =300\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n",
      "Train shape :  (242430, 3)\n",
      "Found 102901 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./input/train.csv\")\n",
    "df_test = pd.read_csv(\"./input/test.csv\")\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "print(\"Test shape : \",df_test.shape)\n",
    "\n",
    "df_train_pos = df_train[df_train['target']==1]\n",
    "df_train_neg = df_train[df_train['target']==0].sample(len(df_train_pos)*2,random_state=1)\n",
    "df_train = pd.concat([df_train_pos,df_train_neg])\n",
    "df_train = df_train.sample(frac=1,random_state=1)\n",
    "print(\"Train shape : \",df_train.shape)\n",
    "\n",
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH=150\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df_train['question_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df_train['question_text'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "train_X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "train_Y = df_train['target']\n",
    "# labels = to_categorical(np.asarray(labels))\n",
    "# print('Shape of data tensor:', data.shape)\n",
    "# print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "# indices = np.arange(data.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# data = data[indices]\n",
    "# labels = labels[indices]\n",
    "# nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "# x_train = data[:-nb_validation_samples]\n",
    "# y_train = labels[:-nb_validation_samples]\n",
    "# x_val = data[-nb_validation_samples:]\n",
    "# y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do some followers of Jainism roam naked and no one beat them?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train.iloc[4]['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.44606690591098\n",
      "65.0\n",
      "45.79357529027139\n",
      "1017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.87777e+05, 4.78110e+04, 6.83700e+03, 3.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00]),\n",
       " array([1.000e+00, 1.026e+02, 2.042e+02, 3.058e+02, 4.074e+02, 5.090e+02,\n",
       "        6.106e+02, 7.122e+02, 8.138e+02, 9.154e+02, 1.017e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for sent in df_train['question_text']:\n",
    "#     print(sent)\n",
    "    lengths.append(len(sent))\n",
    "#     if max(sent)>50:\n",
    "#         print(sent)\n",
    "print(np.mean(lengths))\n",
    "print(np.median(lengths))\n",
    "print(np.std(lengths))\n",
    "print(np.max(lengths))\n",
    "plt.hist(lengths,density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for google word2vec\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        word_vector = word_vectors[word]\n",
    "#     if word_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = word_vector\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242430, 150)\n",
      "(242430,)\n"
     ]
    }
   ],
   "source": [
    "# print(train_X_raw[0])\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    '''\n",
    "    metric from here \n",
    "    https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "    '''\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    # So we only measure F1 on the target y value:\n",
    "    y_true = y_true[:, 0]\n",
    "    y_pred = y_pred[:, 0]\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 300)          30870600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 300)          542400    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               4500100   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 35,913,201\n",
      "Trainable params: 5,042,601\n",
      "Non-trainable params: 30,870,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False))\n",
    "\n",
    "\n",
    "# model.add(CuDNNLSTM(75, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Bidirectional(CuDNNLSTM(150, return_sequences=True), input_shape=(train_X.shape[1], EMBEDDING_DIM)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 193944 samples, validate on 48486 samples\n",
      "Epoch 1/100\n",
      "193944/193944 [==============================] - 49s 251us/step - loss: 0.4325 - acc: 0.8412 - f1: 0.7536 - val_loss: 0.3386 - val_acc: 0.8701 - val_f1: 0.7953\n",
      "Epoch 2/100\n",
      "193944/193944 [==============================] - 46s 238us/step - loss: 0.3846 - acc: 0.8539 - f1: 0.7820 - val_loss: 0.3671 - val_acc: 0.8407 - val_f1: 0.7137\n",
      "Epoch 3/100\n",
      "193944/193944 [==============================] - 47s 243us/step - loss: 0.4332 - acc: 0.8437 - f1: 0.7380 - val_loss: 0.3583 - val_acc: 0.8681 - val_f1: 0.7973\n",
      "Epoch 4/100\n",
      "193944/193944 [==============================] - 48s 246us/step - loss: 0.3425 - acc: 0.8653 - f1: 0.7997 - val_loss: 0.3618 - val_acc: 0.8695 - val_f1: 0.8197\n",
      "Epoch 5/100\n",
      "193944/193944 [==============================] - 49s 251us/step - loss: 0.3672 - acc: 0.8554 - f1: 0.7793 - val_loss: 0.3708 - val_acc: 0.8663 - val_f1: 0.7789\n",
      "Epoch 6/100\n",
      "193944/193944 [==============================] - 49s 251us/step - loss: 0.3419 - acc: 0.8663 - f1: 0.7968 - val_loss: 0.3470 - val_acc: 0.8688 - val_f1: 0.8121\n",
      "Epoch 7/100\n",
      "193944/193944 [==============================] - 47s 244us/step - loss: 0.3408 - acc: 0.8638 - f1: 0.7874 - val_loss: 0.3498 - val_acc: 0.8743 - val_f1: 0.8293\n",
      "Epoch 8/100\n",
      "193944/193944 [==============================] - 48s 247us/step - loss: 0.3912 - acc: 0.8320 - f1: 0.6874 - val_loss: 0.3625 - val_acc: 0.8491 - val_f1: 0.7610\n",
      "Epoch 9/100\n",
      "193944/193944 [==============================] - 48s 245us/step - loss: 0.3359 - acc: 0.8676 - f1: 0.7897 - val_loss: 0.3222 - val_acc: 0.8779 - val_f1: 0.8126\n",
      "Epoch 10/100\n",
      "193944/193944 [==============================] - 49s 252us/step - loss: 0.3123 - acc: 0.8815 - f1: 0.8245 - val_loss: 0.3025 - val_acc: 0.8868 - val_f1: 0.8230\n",
      "Epoch 11/100\n",
      "193944/193944 [==============================] - 48s 250us/step - loss: 0.3789 - acc: 0.8543 - f1: 0.7623 - val_loss: 0.5769 - val_acc: 0.6992 - val_f1: 0.1677\n",
      "Epoch 12/100\n",
      "193944/193944 [==============================] - 48s 250us/step - loss: 0.3369 - acc: 0.8622 - f1: 0.7772 - val_loss: 0.3131 - val_acc: 0.8738 - val_f1: 0.7939\n",
      "Epoch 13/100\n",
      "193944/193944 [==============================] - 48s 249us/step - loss: 0.3048 - acc: 0.8845 - f1: 0.8289 - val_loss: 0.3049 - val_acc: 0.8895 - val_f1: 0.8355\n",
      "Epoch 14/100\n",
      "193944/193944 [==============================] - 48s 250us/step - loss: 0.3471 - acc: 0.8596 - f1: 0.7429 - val_loss: 0.5076 - val_acc: 0.7403 - val_f1: 0.3825\n",
      "Epoch 15/100\n",
      "193944/193944 [==============================] - 48s 250us/step - loss: 0.3757 - acc: 0.8595 - f1: 0.7706 - val_loss: 0.3439 - val_acc: 0.8835 - val_f1: 0.8316\n",
      "Epoch 16/100\n",
      "193944/193944 [==============================] - 48s 250us/step - loss: 0.3888 - acc: 0.8365 - f1: 0.7288 - val_loss: 0.3345 - val_acc: 0.8754 - val_f1: 0.8167\n",
      "Epoch 17/100\n",
      "193944/193944 [==============================] - 48s 249us/step - loss: 0.3200 - acc: 0.8777 - f1: 0.8114 - val_loss: 0.3284 - val_acc: 0.8764 - val_f1: 0.8250\n",
      "Epoch 18/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.3430 - acc: 0.8603 - f1: 0.7524 - val_loss: 0.4287 - val_acc: 0.7638 - val_f1: 0.4561\n",
      "Epoch 19/100\n",
      "193944/193944 [==============================] - 48s 249us/step - loss: 0.3145 - acc: 0.8735 - f1: 0.7924 - val_loss: 0.3109 - val_acc: 0.8873 - val_f1: 0.8307\n",
      "Epoch 20/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.3072 - acc: 0.8754 - f1: 0.7926 - val_loss: 0.2954 - val_acc: 0.8870 - val_f1: 0.8189\n",
      "Epoch 21/100\n",
      "193944/193944 [==============================] - 48s 247us/step - loss: 0.2989 - acc: 0.8858 - f1: 0.8200 - val_loss: 0.3425 - val_acc: 0.8316 - val_f1: 0.6766\n",
      "Epoch 22/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.2974 - acc: 0.8882 - f1: 0.8256 - val_loss: 0.2850 - val_acc: 0.8911 - val_f1: 0.8282\n",
      "Epoch 23/100\n",
      "193944/193944 [==============================] - 48s 247us/step - loss: 0.2830 - acc: 0.8934 - f1: 0.8372 - val_loss: 0.3025 - val_acc: 0.8939 - val_f1: 0.8430\n",
      "Epoch 24/100\n",
      "193944/193944 [==============================] - 48s 246us/step - loss: 0.3268 - acc: 0.8826 - f1: 0.8077 - val_loss: 0.3505 - val_acc: 0.8861 - val_f1: 0.8357\n",
      "Epoch 25/100\n",
      "193944/193944 [==============================] - 48s 249us/step - loss: 0.3811 - acc: 0.8522 - f1: 0.7274 - val_loss: 0.3690 - val_acc: 0.8753 - val_f1: 0.8161\n",
      "Epoch 26/100\n",
      "193944/193944 [==============================] - 49s 251us/step - loss: 0.3909 - acc: 0.8488 - f1: 0.7186 - val_loss: 0.3203 - val_acc: 0.8854 - val_f1: 0.8309\n",
      "Epoch 27/100\n",
      "193944/193944 [==============================] - 50s 255us/step - loss: 0.3038 - acc: 0.8868 - f1: 0.8309 - val_loss: 0.2975 - val_acc: 0.8906 - val_f1: 0.8324\n",
      "Epoch 28/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.2926 - acc: 0.8875 - f1: 0.8226 - val_loss: 0.2938 - val_acc: 0.8932 - val_f1: 0.8371\n",
      "Epoch 29/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.2781 - acc: 0.8969 - f1: 0.8459 - val_loss: 0.2954 - val_acc: 0.8944 - val_f1: 0.8412\n",
      "Epoch 30/100\n",
      "193944/193944 [==============================] - 48s 248us/step - loss: 0.4324 - acc: 0.8438 - f1: 0.6733 - val_loss: 0.4373 - val_acc: 0.7692 - val_f1: 0.4752\n",
      "Epoch 31/100\n",
      "193500/193944 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8742 - f1: 0.7761"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, epochs=100,batch_size=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D, Flatten\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Conv2D(10,(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# model.build()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letter_count = dict(zip(string.ascii_lowercase, [0]*26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{chr(i+96):i for i in range(1,27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
